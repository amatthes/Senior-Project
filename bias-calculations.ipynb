{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54414a3b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e310e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import FaderNetworks Directory\n",
    "import sys\n",
    "sys.path.append('../FaderNetworks')\n",
    "\n",
    "from src.logger import create_logger\n",
    "from src.loader import load_images, DataSampler\n",
    "from src.utils import bool_flag\n",
    "from src.loader import AVAILABLE_ATTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c941a8b",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4f5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Use classifier to classify counterfactual interpolations\n",
    "def classifications(model, interpolations):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    mod = torch.load(model).eval()\n",
    "    interps = torch.load(interpolations).to(device)\n",
    "    outputs = []\n",
    "    for x in interps:\n",
    "        outputs.append(mod(x))\n",
    "    # Take the second value in each pair\n",
    "    new_outputs = []\n",
    "    for tensor1 in outputs:\n",
    "        tens1 = []\n",
    "        for tensor2 in tensor1:\n",
    "            tens2 = []\n",
    "            for x in range(0,80,2):\n",
    "                tens2.append(sig(tensor2[x+1].cpu().detach().numpy()))\n",
    "            tens1.append(tens2)\n",
    "        new_outputs.append(tens1)\n",
    "    return new_outputs\n",
    "\n",
    "\n",
    "# Get the classification outputs for the interpolations for one single attribute without including the first 2 images\n",
    "def isolate_attribute(outputs, attribute):\n",
    "    attribute_classifications = []\n",
    "    \n",
    "    for i in outputs:\n",
    "        face = []\n",
    "        for x in i:\n",
    "            face.append(x[AVAILABLE_ATTR.index(attribute)]) #not including the first 2 images\n",
    "        attribute_classifications.append(face[2:])\n",
    "    return attribute_classifications\n",
    "\n",
    "# Isolate a single attribute along with the original images\n",
    "def isolate_attribute_with_orig(outputs, attribute):\n",
    "    attribute_classifications = []\n",
    "    for i in outputs:\n",
    "        face = []\n",
    "        for x in i:\n",
    "            face.append(x[AVAILABLE_ATTR.index(attribute)]) #including the first 2 images\n",
    "        attribute_classifications.append(face)\n",
    "    return attribute_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff272c",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE error in FaderNetworks\n",
    "# Compare the classifciation values of the first face to the interpolated face with the most similar value\n",
    "def error(outputs, attr):\n",
    "    attribute_classifications = []\n",
    "    \n",
    "    # Find the faces most similar to the original in the grid\n",
    "    for i in outputs:\n",
    "        face = []\n",
    "        for x in i:\n",
    "            face.append(x[AVAILABLE_ATTR.index(attr)])\n",
    "        attribute_classifications.append(face)\n",
    "        \n",
    "    face_index_arr = []\n",
    "    for face in attribute_classifications:\n",
    "        orig = face[0]\n",
    "        diff = 999\n",
    "        curr = 2\n",
    "        for i in range(2,12):\n",
    "            if(abs(face[i]- orig) < diff):\n",
    "                diff = face[i]- orig\n",
    "                curr = i\n",
    "        face_index_arr.append(curr)\n",
    "        \n",
    "    # Sum all the error\n",
    "    sum = 0\n",
    "    total = 0\n",
    "    for attribute in AVAILABLE_ATTR:\n",
    "        attribute_classifications = isolate_attribute_with_orig(outputs, attribute)\n",
    "        ind = 0\n",
    "        for face in attribute_classifications:\n",
    "            sum += (face[0] - face[face_index_arr[ind]])**2\n",
    "            ind+=1\n",
    "            total+=1\n",
    "    return (sum/total) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89277fea",
   "metadata": {},
   "source": [
    "# Bias Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_boundary(outputs, prot_attr):\n",
    "    \n",
    "    attr_classifications = isolate_attribute(outputs, prot_attr)\n",
    "    boundary = np.average(attr_classifications)\n",
    "    \n",
    "    attr_boundary = []\n",
    "    for face in attr_classifications:\n",
    "        for i in range(0,10):\n",
    "            if face[i] >= boundary:\n",
    "                attr_boundary.append(i)\n",
    "                break\n",
    "            if i == 9:\n",
    "                attr_boundary.append(8)\n",
    "        return attr_boundary\n",
    "def co_occurrence_bias(outputs, attribute):\n",
    "    biases = []\n",
    "    prot_boundary = get_attr_boundary(outputs, attribute)\n",
    "    \n",
    "    for attribute in AVAILABLE_ATTR:\n",
    "        attribute_classifications = isolate_attribute(outputs, attribute)\n",
    "        boundary = np.average(attribute_classifications)\n",
    "        \n",
    "        g = 0\n",
    "        g_prime = 0\n",
    "        ind = 0\n",
    "        for face in attribute_classifications:\n",
    "            for i in range(0,prot_boundary[ind]):\n",
    "                if face[i] > boundary:\n",
    "                    g_prime+=1\n",
    "            for i in range(prot_boundary[ind],10):\n",
    "                if face[i] > boundary:\n",
    "                    g+=1\n",
    "            ind+=1\n",
    "        bias_score = (g / (g + g_prime)) - (1/2)\n",
    "        biases.append(bias_score)\n",
    "    return biases\n",
    "\n",
    "def demographic_parity(outputs, prot_attr):\n",
    "    biases = []\n",
    "    g_boundary = get_attr_boundary(outputs, prot_attr)\n",
    "    \n",
    "    for attribute in AVAILABLE_ATTR:\n",
    "        attribute_classifications = isolate_attribute(outputs, attribute)\n",
    "        exp_sum = 0\n",
    "        zg = 0.5\n",
    "        ind = 0\n",
    "        for face in attribute_classifications:\n",
    "            for i in range(0,g_boundary[ind]): #g(x) = 0\n",
    "                exp_sum += face[i]*(-1)\n",
    "            for i in range(g_boundary[ind],10): #g(x) = 1\n",
    "                exp_sum += face[i]*(1/zg - 1)\n",
    "            ind+=1\n",
    "        biases.append(exp_sum/40)\n",
    "    return biases\n",
    "\n",
    "def equal_opportunity(outputs, prot_attr):\n",
    "    biases = []\n",
    "    g_boundary = get_attr_boundary(outputs, prot_attr)\n",
    "    \n",
    "    for attribute in AVAILABLE_ATTR:\n",
    "        attribute_classifications = isolate_attribute(outputs, attribute)\n",
    "        true_boundary = np.percentile(attribute_classifications, 75)\n",
    "        exp_sum = 0\n",
    "        ytrue = 1\n",
    "        ind = 0\n",
    "        for face in attribute_classifications:\n",
    "            px = 0\n",
    "            pg = 0\n",
    "            for i in range(0,10):\n",
    "                if face[i] > true_boundary:\n",
    "                    px+=1\n",
    "                    if i >= g_boundary[ind]:\n",
    "                        pg+=1\n",
    "            px = px/10\n",
    "            pg = pg/10\n",
    "            ind = 0\n",
    "            for i in range(0,g_boundary[ind]):#g(x) = 0\n",
    "                if(face[i] > true_boundary):\n",
    "                    exp_sum += face[i]*(-(ytrue)/px)\n",
    "            for i in range(g_boundary[ind],10):#g(x) = 1\n",
    "                if(face[i] > true_boundary and pg != 0):\n",
    "                    exp_sum += face[i]*(ytrue/pg - ytrue/px)\n",
    "                #exp_sum += face[i]*(ytrue/0.5 - ytrue/px)\n",
    "            ind+=1\n",
    "        biases.append(exp_sum/40)\n",
    "    return biases\n",
    "\n",
    "\n",
    "def equalized_odds(outputs, prot_attr):\n",
    "    biases = []\n",
    "    g_boundary = get_attr_boundary(outputs, prot_attr)\n",
    "    \n",
    "    for attribute in AVAILABLE_ATTR:\n",
    "        attribute_classifications = isolate_attribute(outputs, attribute)\n",
    "        true_boundary = np.percentile(attribute_classifications, 75)\n",
    "        \n",
    "        exp_sum = 0\n",
    "        zg = 0.5\n",
    "        ind = 0\n",
    "        for face in attribute_classifications:\n",
    "            px = 0\n",
    "            pg = 0\n",
    "            for i in range(0,10):\n",
    "                if face[i] > true_boundary:\n",
    "                    px+=1\n",
    "                    if i > 4:\n",
    "                        pg+=1\n",
    "            px = px/10\n",
    "            pg = pg/10\n",
    "            ind = 0\n",
    "            for i in range(0,g_boundary[ind]): #g(x) = 0\n",
    "                if(face[i] < true_boundary):\n",
    "                    exp_sum += face[i]*(-(1)/(1-px))\n",
    "            for i in range(g_boundary[ind],10): #g(x) = 1\n",
    "                if(face[i] < true_boundary and (zg - pg) != 0):\n",
    "                    exp_sum += face[i]*((1)/(zg - pg) - (1)/(1-px))\n",
    "            ind+=1\n",
    "            \n",
    "        biases.append(exp_sum/40)\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339a033",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attribute_grid(outputs):\n",
    "    fig, axs = plt.subplots(10, 3)\n",
    "    #2, 24, 31 attractive, no_beard, and smiling\n",
    "    \n",
    "    smiling_classifications = isolate_attribute(outputs, \"Smiling\")\n",
    "    attractive_classifications = isolate_attribute(outputs, \"Attractive\")\n",
    "    no_beard_classifications = isolate_attribute(outputs, \"No_Beard\")\n",
    "    \n",
    "    axs[0,0].plot(smiling_classifications[0])\n",
    "    axs[0, 0].set_title('Smiling Classifications')\n",
    "    axs[1,0].plot(smiling_classifications[1])\n",
    "    axs[2,0].plot(smiling_classifications[2])\n",
    "    axs[3,0].plot(smiling_classifications[3])\n",
    "    axs[4,0].plot(smiling_classifications[4])\n",
    "    axs[5,0].plot(smiling_classifications[5])\n",
    "    axs[6,0].plot(smiling_classifications[6])\n",
    "    axs[7,0].plot(smiling_classifications[7])\n",
    "    axs[8,0].plot(smiling_classifications[8])\n",
    "    axs[9,0].plot(smiling_classifications[9])\n",
    "    \n",
    "    axs[0,1].plot(attractive_classifications[0])\n",
    "    axs[0, 1].set_title('Attracive Classifications')\n",
    "    axs[1,1].plot(attractive_classifications[1])\n",
    "    axs[2,1].plot(attractive_classifications[2])\n",
    "    axs[3,1].plot(attractive_classifications[3])\n",
    "    axs[4,1].plot(attractive_classifications[4])\n",
    "    axs[5,1].plot(attractive_classifications[5])\n",
    "    axs[6,1].plot(attractive_classifications[6])\n",
    "    axs[7,1].plot(attractive_classifications[7])\n",
    "    axs[8,1].plot(attractive_classifications[8])\n",
    "    axs[9,1].plot(attractive_classifications[9])\n",
    "    \n",
    "    axs[0,2].plot(no_beard_classifications[0])\n",
    "    axs[0, 2].set_title('No Beard Classifications')\n",
    "    axs[1,2].plot(no_beard_classifications[0])\n",
    "    axs[2,2].plot(no_beard_classifications[0])\n",
    "    axs[3,2].plot(no_beard_classifications[0])\n",
    "    axs[4,2].plot(no_beard_classifications[0])\n",
    "    axs[5,2].plot(no_beard_classifications[0])\n",
    "    axs[6,2].plot(no_beard_classifications[0])\n",
    "    axs[7,2].plot(no_beard_classifications[0])\n",
    "    axs[8,2].plot(no_beard_classifications[0])\n",
    "    axs[9,2].plot(no_beard_classifications[0])\n",
    "    \n",
    "def plot_attribute_bias(biases, title, color):\n",
    "    x = list(range(40))\n",
    "    plt.barh(x,biases, tick_label=AVAILABLE_ATTR, color = color)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "\n",
    "def plot_multiple_bias(bias1, bias2, bias3, bias4):\n",
    "    width = 0.3\n",
    "    x = np.arange(40)\n",
    "    xvals = bias1\n",
    "    bar1 = plt.barh(x, xvals, width, color = 'r')\n",
    "    yvals = bias2\n",
    "    bar2 = plt.barh(x+width, yvals, width, color='g')\n",
    "    zvals = bias3\n",
    "    bar3 = plt.barh(x+width*2, zvals, width, color = 'b')\n",
    "    avals = bias4\n",
    "    bar4 = plt.barh(x+width*3, avals, width, color = 'y')\n",
    "    \n",
    "    plt.ylabel('Scores')\n",
    "    plt.title(\"Young Interpolations Bias\")\n",
    "    plt.yticks(x+width, AVAILABLE_ATTR)\n",
    "    plt.legend( (bar1, bar2, bar3,bar4), ('co-occurence', 'Demographic Parity', 'Equal Opportunity', 'Equalized Odds') )\n",
    "    plt.show()\n",
    "    \n",
    "def plot_grid(bar1, bar2, bar3, bar4, title):\n",
    "    x = np.arange(40)\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    axs[0, 0].barh(x, bar1, tick_label = AVAILABLE_ATTR)\n",
    "    axs[0, 0].set_title('Co-Occurance Bias')\n",
    "    axs[0, 0].grid(which='minor', alpha=0.1)\n",
    "    axs[0, 0].grid(which='major', alpha=0.2)\n",
    "    axs[0, 1].barh(x, bar2, color = 'orange', tick_label = AVAILABLE_ATTR)\n",
    "    axs[0, 1].set_title('Demographic Parity')\n",
    "    axs[0, 1].grid(which='minor', alpha=0.1)\n",
    "    axs[0, 1].grid(which='major', alpha=0.2)\n",
    "    axs[1, 1].barh(x, bar3, color = 'green', tick_label = AVAILABLE_ATTR)\n",
    "    axs[1, 1].set_title('Equal Opportunity')\n",
    "    axs[1, 1].grid(which='minor', alpha=0.1)\n",
    "    axs[1, 1].grid(which='major', alpha=0.2)\n",
    "    axs[1, 0].barh(x, bar4, color = 'red', tick_label = AVAILABLE_ATTR)\n",
    "    axs[1, 0].set_title('Equalized Odds')\n",
    "    axs[1, 0].grid(which='minor', alpha=0.1)\n",
    "    axs[1, 0].grid(which='major', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d621adf",
   "metadata": {},
   "source": [
    "# Young Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "young_outputs = classifications('classifier256.pth', 'young_interpolations.pth')\n",
    "co_bias = co_occurrence_bias(young_outputs, \"Young\")\n",
    "dem_par = demographic_parity(young_outputs, \"Young\")\n",
    "eq_opp = equal_opportunity(young_outputs, \"Young\")\n",
    "eq_odds = equalized_odds(young_outputs, \"Young\")\n",
    "plot_grid(co_bias, dem_par, eq_opp, eq_odds, \"Bias on the Young Attribute\")\n",
    "plot_attribute_grid(young_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa789337",
   "metadata": {},
   "source": [
    "# Male Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ae60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_outputs = classifications('classifier256.pth', 'male_interpolations.pth')\n",
    "co_bias = co_occurrence_bias(male_outputs, \"Male\")\n",
    "dem_par = demographic_parity(male_outputs, \"Male\")\n",
    "eq_opp = equal_opportunity(male_outputs, \"Male\")\n",
    "eq_odds = equalized_odds(male_outputs, \"Male\")\n",
    "plot_grid(co_bias, dem_par, eq_opp, eq_odds, \"Bias on the Male Attribute\")\n",
    "plot_attribute_grid(male_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41001f09",
   "metadata": {},
   "source": [
    "# Eyeglasses Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5adf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeglasses_outputs = classifications('classifier256.pth', 'eyeglasses_interpolations.pth')\n",
    "co_bias = co_occurrence_bias(eyeglasses_outputs, \"Male\")\n",
    "dem_par = demographic_parity(eyeglasses_outputs, \"Male\")\n",
    "eq_opp = equal_opportunity(eyeglasses_outputs, \"Male\")\n",
    "eq_odds = equalized_odds(eyeglasses_outputs, \"Male\")\n",
    "plot_grid(co_bias, dem_par, eq_opp, eq_odds, \"Bias on the Eyeglasses Attribute\")\n",
    "plot_attribute_grid(eyeglasses_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
